# Makefile - Guia de Comandos

Este Makefile fornece comandos convenientes para gerenciar todo o ambiente de agrega√ß√£o de receb√≠veis, incluindo Flink e Spark.

## üìã Listar Comandos Dispon√≠veis

```bash
make help
```

## üöÄ In√≠cio R√°pido

### 1. Iniciar Infraestrutura

```bash
# Iniciar todos os servi√ßos (Kafka, Elasticsearch, DynamoDB, Flink, Spark)
make up

# Aguardar servi√ßos iniciarem (30 segundos)
sleep 30

# Inicializar recursos (t√≥picos Kafka, tabelas, √≠ndices)
make init
```

### 2. Executar com Flink

```bash
# Compilar e executar job Flink
make flink-job

# Gerar eventos de teste
make producer

# Validar resultados
make validate
```

### 3. Executar com Spark

```bash
# Iniciar job Spark
make spark-job

# Gerar eventos de teste
make producer

# Validar resultados
make validate

# Parar job Spark
make spark-stop
```

## üìö Comandos Detalhados

### Gerenciamento de Containers

| Comando | Descri√ß√£o |
|---------|-----------|
| `make up` | Inicia todos os servi√ßos |
| `make down` | Para todos os servi√ßos |
| `make restart` | Reinicia todos os servi√ßos |
| `make clean` | Remove containers e volumes |
| `make logs` | Mostra logs de todos os servi√ßos |
| `make status` | Mostra status dos servi√ßos |

### Jobs Flink

| Comando | Descri√ß√£o |
|---------|-----------|
| `make flink-build` | Compila o job Flink (Maven) |
| `make flink-job` | Submete o job Flink para execu√ß√£o |
| `make flink-list` | Lista todos os jobs Flink |
| `make flink-cancel` | Cancela jobs Flink em execu√ß√£o |

### Jobs Spark

| Comando | Descri√ß√£o |
|---------|-----------|
| `make spark-job` | Inicia o job Spark no cluster |
| `make spark-stop` | Para o job Spark |
| `make spark-logs` | Mostra logs do job Spark |
| `make spark-local` | Executa Spark localmente (fora do Docker) |

### Inicializa√ß√£o de Dados

| Comando | Descri√ß√£o |
|---------|-----------|
| `make init` | Inicializa todos os recursos (recomendado) |
| `make init-kafka` | Cria t√≥picos no Kafka |
| `make init-db` | Cria tabela no DynamoDB |
| `make init-es` | Cria √≠ndice no Elasticsearch |

### Testes e Valida√ß√£o

| Comando | Descri√ß√£o |
|---------|-----------|
| `make producer` | Gera 100 eventos de teste |
| `make producer-continuous` | Gera eventos continuamente (2 min) |
| `make validate` | Valida consist√™ncia DynamoDB ‚Üî Elasticsearch |
| `make test-flink` | Pipeline completo de teste com Flink |
| `make test-spark` | Pipeline completo de teste com Spark |

### Utilit√°rios

| Comando | Descri√ß√£o |
|---------|-----------|
| `make kafka-topics` | Lista t√≥picos Kafka |
| `make es-count` | Conta documentos no Elasticsearch |
| `make dynamodb-count` | Conta itens no DynamoDB |
| `make shell-flink` | Abre shell no Flink JobManager |
| `make shell-spark` | Abre shell no Spark Master |
| `make shell-kafka` | Abre shell no Kafka |

## üîß Exemplos de Uso

### Teste Completo com Flink

```bash
# Pipeline completo automatizado
make test-flink

# Ou passo a passo:
make up
make init
make flink-job
make producer
sleep 30
make validate
```

### Teste Completo com Spark

```bash
# Pipeline completo automatizado
make test-spark

# Ou passo a passo:
make up
make init
make spark-job
make producer
sleep 30
make validate
make spark-stop
```

### Comparar Flink vs Spark

```bash
# Testar Flink
make up && make init
make flink-job
make producer-continuous
make validate

# Parar Flink e testar Spark
make flink-cancel
make clean && make up && make init
make spark-job
make producer-continuous
make validate
make spark-stop
```

### Desenvolvimento Iterativo

```bash
# 1. Fazer altera√ß√µes no c√≥digo
# 2. Recompilar Flink
make flink-build

# 3. Cancelar job antigo
make flink-cancel

# 4. Submeter novo job
make flink-job

# Ou para Spark (n√£o precisa compilar)
make spark-stop
make spark-job
```

### Monitoramento Cont√≠nuo

```bash
# Terminal 1: Logs do job
make spark-logs  # ou docker-compose logs -f jobmanager

# Terminal 2: Producer cont√≠nuo
while true; do make producer; sleep 5; done

# Terminal 3: Monitorar contagens
watch -n 2 'make es-count'
```

## üåê URLs dos Servi√ßos

Ap√≥s `make up`, os seguintes servi√ßos estar√£o dispon√≠veis:

| Servi√ßo | URL | Descri√ß√£o |
|---------|-----|-----------|
| Kafka UI | http://localhost:8090 | Interface web para Kafka |
| Elasticsearch | http://localhost:9200 | API REST do Elasticsearch |
| DynamoDB Admin | http://localhost:8001 | Interface web para DynamoDB |
| Flink Dashboard | http://localhost:8081 | Dashboard do Flink |
| Spark UI | http://localhost:8082 | Interface web do Spark |

## üêõ Troubleshooting

### Jobs n√£o aparecem no Flink

```bash
# Verificar se JobManager est√° rodando
docker ps | grep flink

# Ver logs do JobManager
docker logs flink-jobmanager

# Listar jobs
make flink-list
```

### Spark job n√£o inicia

```bash
# Ver logs detalhados
make spark-logs

# Verificar se Spark Master est√° rodando
docker ps | grep spark

# Reiniciar servi√ßos Spark
docker-compose restart spark-master spark-worker
make spark-job
```

### Kafka n√£o conecta

```bash
# Verificar t√≥picos
make kafka-topics

# Reinicializar Kafka
docker-compose restart kafka zookeeper
sleep 10
make init-kafka
```

### Elasticsearch n√£o responde

```bash
# Verificar sa√∫de do cluster
curl http://localhost:9200/_cluster/health?pretty

# Recriar √≠ndice
curl -X DELETE http://localhost:9200/ciclo_vida_recebiveis
make init-es
```

### DynamoDB vazio

```bash
# Verificar tabela
aws dynamodb describe-table --table-name Recebiveis \
  --endpoint-url http://localhost:8000 --region us-east-1

# Recriar tabela
make init-db
```

## üìù Notas Importantes

1. **Ordem de Execu√ß√£o**: Sempre execute `make up` antes de outros comandos
2. **Inicializa√ß√£o**: Execute `make init` ap√≥s `make up` na primeira vez
3. **Aguardar**: D√™ tempo para os servi√ßos iniciarem completamente (~30s)
4. **Limpeza**: Use `make clean` para reset completo do ambiente
5. **Profiles**: O Spark job usa profile `spark-streaming` no docker-compose

## üîç Verificar Status

```bash
# Status geral
make status

# Status detalhado
docker-compose ps
```

## üéØ Workflows Recomendados

### Desenvolvimento Flink
```bash
make up
make init
# Editar c√≥digo Java
make flink-build
make flink-cancel  # se j√° houver job rodando
make flink-job
make producer
make validate
```

### Desenvolvimento Spark
```bash
make up
make init
# Editar c√≥digo Python
make spark-stop  # se j√° houver job rodando
make spark-job
make producer
make validate
```

### Demo/Apresenta√ß√£o
```bash
# Mostrar Flink
make test-flink

# Limpar e mostrar Spark
make clean
make test-spark
```

## üí° Dicas

- Use `make help` para lembrar dos comandos
- Combine comandos: `make up && make init && make flink-job`
- Use `&` para rodar em background: `make producer &`
- Monitore logs em tempo real: `make logs`
- Acesse as UIs web para visualiza√ß√£o gr√°fica
